# ACIT-PIP
This repository will soon be updated with Python code and pretrained models for pedestrian crossing intention prediction networks as presented in our paper:
“ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction.” (accepted in IEEE ITSC 2025)

The proposed model integrates six visual and motion modalities, organized into three interaction pairs to facilitate deep cross-modal interactions:
1. Global semantic map and global optical flow
2. Local RGB image and local optical flow
3. Ego-vehicle speed and pedestrian bounding box
All experiments are conducted on the JAAD dataset, and we comprehensively compare the performance of our model against a range of baseline methods.


![架构final](https://github.com/user-attachments/assets/2fe4d0d0-5819-4c81-9797-ca6c8ac43642)

